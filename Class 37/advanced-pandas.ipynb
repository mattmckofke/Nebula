{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ **Advanced Data Analysis Assignment**\n",
                "\n",
                "Welcome to the next-level assignment! We‚Äôll build on the two previous datasets:\n",
                "1. A **region-based** dataset containing `Region`, `Sales`, and `Transactions`.\n",
                "2. A **time-series** dataset containing daily `Sales` from 2020-01-01 to 2020-12-31.\n",
                "\n",
                "In this notebook, you will:\n",
                "1. Load and explore both datasets.\n",
                "2. Perform advanced grouping and pivoting on the regional data.\n",
                "3. Check correlations and detect potential outliers.\n",
                "4. Conduct advanced time-series analysis (rolling means & seasonal decomposition).\n",
                "5. Provide concise insights from your findings.\n",
                "\n",
                "Let\"s get started! üéâ\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß© **Part A: Advanced Analysis on Regional Sales Data**\n",
                "We\"ll begin by re-generating (or reloading) the regional sales data from your previous assignment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Region</th>\n",
                            "      <th>Sales</th>\n",
                            "      <th>Transactions</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>North</td>\n",
                            "      <td>570.196770</td>\n",
                            "      <td>29</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>West</td>\n",
                            "      <td>438.601513</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>South</td>\n",
                            "      <td>988.373838</td>\n",
                            "      <td>28</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>North</td>\n",
                            "      <td>102.044811</td>\n",
                            "      <td>84</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>West</td>\n",
                            "      <td>208.876756</td>\n",
                            "      <td>90</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  Region       Sales  Transactions\n",
                            "0  North  570.196770            29\n",
                            "1   West  438.601513             3\n",
                            "2  South  988.373838            28\n",
                            "3  North  102.044811            84\n",
                            "4   West  208.876756            90"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# === Part A: Data Generation (Regional) ===\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Seed for reproducibility\n",
                "np.random.seed(0)\n",
                "\n",
                "# Generate random data\n",
                "data_regional = {\n",
                "    \"Region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], size=100),\n",
                "    \"Sales\": np.random.rand(100) * 1000,  # Sales figures between 0 and 1000\n",
                "    \"Transactions\": np.random.randint(1, 100, size=100)  # Transactions between 1 and 100\n",
                "}\n",
                "\n",
                "# Create DataFrame\n",
                "df_regional = pd.DataFrame(data_regional)\n",
                "df_regional.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîç **Task A1: Exploratory Data Analysis**\n",
                "1. Display basic summary statistics for `Sales` and `Transactions`.\n",
                "2. Identify the number of unique regions.\n",
                "3. Check for any missing values.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "            Sales  Transactions\n",
                        "count  100.000000    100.000000\n",
                        "mean   496.438899     48.440000\n",
                        "std    283.716158     28.051655\n",
                        "min      4.695476      1.000000\n",
                        "25%    262.365019     28.750000\n",
                        "50%    544.924754     44.500000\n",
                        "75%    700.581602     72.500000\n",
                        "max    998.847007     98.000000\n",
                        "\n",
                        "4\n",
                        "\n",
                        "Region          0\n",
                        "Sales           0\n",
                        "Transactions    0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task A1 ===\n",
                "\n",
                "# 1) Basic summary statistics\n",
                "\n",
                "print(df_regional.describe())\n",
                "print()\n",
                "# 2) Number of unique regions\n",
                "\n",
                "print(df_regional[\"Region\"].nunique())\n",
                "print()\n",
                "\n",
                "# 3) Check for missing values\n",
                "\n",
                "print(df_regional.isnull().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üíπ **Task A2: Pivot Table & Group Analysis**\n",
                "1. Create a pivot table showing the **average Sales** and **average Transactions** by `Region`.\n",
                "2. Sort the pivot table by the highest average Sales.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Region\n",
                        "East     564.093444\n",
                        "North    515.117684\n",
                        "South    466.730246\n",
                        "West     463.957703\n",
                        "Name: Sales, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task A2 ===\n",
                "\n",
                "# Sort by highest average Sales\n",
                "\n",
                "print(df_regional.groupby(\"Region\")[\"Sales\"].mean().sort_values(ascending=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚öóÔ∏è **Task A3: Correlation & Outlier Detection** ‚ö†Ô∏è Optional Challenge\n",
                "1. Calculate the correlation between `Sales` and `Transactions`. Do they appear to be correlated?\n",
                "2. Detect potential outliers in `Sales` using the **IQR** (Interquartile Range) method.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "-0.017727723478534588\n",
                        "\n",
                        "   Region       Sales  Transactions\n",
                        "0   North  570.196770            29\n",
                        "1    West  438.601513             3\n",
                        "2   South  988.373838            28\n",
                        "3   North  102.044811            84\n",
                        "4    West  208.876756            90\n",
                        "..    ...         ...           ...\n",
                        "95  North  703.888584            74\n",
                        "96   East  100.226887            29\n",
                        "97   West  919.482614            82\n",
                        "98  South  714.241300            59\n",
                        "99  North  998.847007             1\n",
                        "\n",
                        "[100 rows x 3 columns]\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task A3 ===\n",
                "# 1) Correlation\n",
                "\n",
                "print(df_regional[\"Sales\"].corr(df_regional[\"Transactions\"]))\n",
                "print()\n",
                "\n",
                "# 2) Outlier Detection using IQR\n",
                "\n",
                "print(df_regional[(df_regional[\"Sales\"] < 0.25) | (df_regional[\"Sales\"] > 0.75)])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìà **Part B: Advanced Time-Series Analysis**\n",
                "Now let\"s work with the **time-series** dataset from your second assignment. We\"ll generate (or reload) the data below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# === Part B: Data Generation (Time-Series) ===\n",
                "dates = pd.date_range(start=\"2020-01-01\", end=\"2020-12-31\", freq=\"D\")\n",
                "data_timeseries = {\n",
                "    \"Date\": dates,\n",
                "    \"Sales\": (\n",
                "        np.random.rand(len(dates)) * 200\n",
                "        + np.sin(np.linspace(-3, 3, len(dates))) * 50\n",
                "        + 100\n",
                "    ),\n",
                "}\n",
                "\n",
                "df_timeseries = pd.DataFrame(data_timeseries)\n",
                "df_timeseries.set_index(\"Date\", inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîé **Task B1: Quick Exploration**\n",
                "1. Display the first 5 rows.\n",
                "2. Show a statistical summary of the `Sales` column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                 Sales\n",
                        "Date                  \n",
                        "2020-01-01  184.146924\n",
                        "2020-01-02  273.414915\n",
                        "2020-01-03  118.764805\n",
                        "2020-01-04  136.356354\n",
                        "2020-01-05  266.023902\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task B1 ===\n",
                "# 1) Display first 5 rows\n",
                "\n",
                "print(df_timeseries.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "count    366.000000\n",
                        "mean     200.792224\n",
                        "std       67.882237\n",
                        "min       51.476035\n",
                        "25%      150.566550\n",
                        "50%      205.306249\n",
                        "75%      247.418375\n",
                        "max      345.914629\n",
                        "Name: Sales, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "# 2) Statistical summary of the \"Sales\" column\n",
                "\n",
                "print(df_timeseries[\"Sales\"].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìÜ **Task B2: Monthly & Rolling Analysis**\n",
                "1. Calculate monthly average `Sales`.\n",
                "2. Compute a 7-day rolling average to smooth out short-term fluctuations.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                 Sales\n",
                        "Date                  \n",
                        "2020-01-31  189.417216\n",
                        "2020-02-29  149.197259\n",
                        "2020-03-31  161.285228\n",
                        "2020-04-30  156.722894\n",
                        "2020-05-31  154.537646\n",
                        "2020-06-30  191.519449\n",
                        "2020-07-31  201.264893\n",
                        "2020-08-31  246.365698\n",
                        "2020-09-30  241.561151\n",
                        "2020-10-31  254.233885\n",
                        "2020-11-30  240.099829\n",
                        "2020-12-31  220.835232\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task B2 ===\n",
                "# 1) Monthly average Sales\n",
                "\n",
                "print(df_timeseries.resample(\"ME\").mean())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                 Sales\n",
                        "Date                  \n",
                        "2020-01-01  184.146924\n",
                        "2020-01-02  228.780919\n",
                        "2020-01-03  192.108881\n",
                        "2020-01-04  178.170750\n",
                        "2020-01-05  195.741380\n",
                        "...                ...\n",
                        "2020-12-27  160.420850\n",
                        "2020-12-28  163.213619\n",
                        "2020-12-29  159.045189\n",
                        "2020-12-30  175.935165\n",
                        "2020-12-31  190.476518\n",
                        "\n",
                        "[366 rows x 1 columns]\n"
                    ]
                }
            ],
            "source": [
                "# 2) 7-day rolling average\n",
                "\n",
                "print(df_timeseries.rolling(window=7, min_periods=1).mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üî¨ **Task B3: Day-of-Week Seasonality Analysis (Using Pandas Only)**\n",
                "\n",
                "1. **Extract the day of the week** from the index and store it in a new column (e.g., `DayOfWeek`).\n",
                "2. **Group by** this `DayOfWeek` column to get the **average Sales** for each day of the week.\n",
                "3. **Compare** these daily averages to see if certain days have higher or lower sales.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DayOfWeek\n",
                        "0    211.709257\n",
                        "1    191.934073\n",
                        "2    201.457314\n",
                        "3    191.662709\n",
                        "4    205.961047\n",
                        "5    194.360662\n",
                        "6    208.623282\n",
                        "Name: Sales, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "# === SOLUTION for Task B3 with Pandas Only ===\n",
                "# 1) Extract day of the week: Monday=0, Sunday=6\n",
                "\n",
                "df_timeseries[\"DayOfWeek\"] = df_timeseries.index.dayofweek\n",
                "\n",
                "# 2) Group by the day of the week to compute average sales\n",
                "\n",
                "print(df_timeseries.groupby(\"DayOfWeek\")[\"Sales\"].mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìù **Observations & Insights**\n",
                "1. **Regional Data**\n",
                "   - The correlation between `Sales` and `Transactions` is quite low, suggesting they‚Äôre not strongly related in this sample.\n",
                "   - Pivot tables show which region averages the highest Sales, with minimal outliers in `Sales`.\n",
                "\n",
                "2. **Time-Series Data**\n",
                "   - The monthly averages reveal slight fluctuations each month.\n",
                "   - The 7-day rolling average smooths out daily noise.\n",
                "   - Seasonal decomposition indicates a clear weekly seasonal pattern (due to the `np.sin()` component) and an overall trend.\n",
                "\n",
                "---\n",
                "## üèÅ **Assignment Wrap-Up**\n",
                "\n",
                "üéâ **Congratulations!** You‚Äôve:\n",
                "- Built pivot tables and looked for regional trends.\n",
                "- Analyzed correlation and outliers.\n",
                "- Explored monthly averages in time-series data.\n",
                "- Investigated rolling averages and seasonal decomposition.\n",
                "\n",
                "These techniques will provide a solid foundation for more advanced analytical work, including forecasting, anomaly detection, and deeper business intelligence. Keep exploring!\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
